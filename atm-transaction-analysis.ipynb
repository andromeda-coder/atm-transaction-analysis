{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/opt/cloudera/parcels/Anaconda/bin/python\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_232-cloudera/jre\"\n",
    "os.environ[\"SPARK_HOME\"]=\"/opt/cloudera/parcels/SPARK2-2.3.0.cloudera2-1.cdh5.13.3.p0.316101/lib/spark2/\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.6-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-0-227.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.cloudera2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SRC_ATM_TRANS</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7cd8046150>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SRC_ATM_TRANS').master(\"local\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", \"your_access_key\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", \"your_secret_key\")\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.endpoint', 's3.us-east-1.amazonaws.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, DoubleType, LongType, TimestampType\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileSchema = StructType([\n",
    "    StructField('year', IntegerType(), True),\n",
    "    StructField('month', StringType(), True),\n",
    "    StructField('day', IntegerType(), True),\n",
    "    StructField('weekday', StringType(), True),\n",
    "    StructField('hour', IntegerType(), True),\n",
    "    StructField('atm_status', StringType(), True),\n",
    "    StructField('atm_id', IntegerType(), True),\n",
    "    StructField('atm_manufacturer', StringType(), True),\n",
    "    StructField('atm_location', StringType(), True),\n",
    "    StructField('atm_streetname', StringType(), True),\n",
    "    StructField('atm_street_number', IntegerType(), True),\n",
    "    StructField('atm_zipcode', IntegerType(), True),\n",
    "    StructField('atm_lat', DoubleType(), True),\n",
    "    StructField('atm_lon', DoubleType(), True),\n",
    "    StructField('currency', StringType(), True),\n",
    "    StructField('card_type', StringType(), True),\n",
    "    StructField('transaction_amount', IntegerType(), True),\n",
    "    StructField('service', StringType(), True),\n",
    "    StructField('message_code', StringType(), True),\n",
    "    StructField('message_text', StringType(), True),\n",
    "    StructField('weather_lat', DoubleType(), True),\n",
    "    StructField('weather_lon', DoubleType(), True),\n",
    "    StructField('weather_city_id', IntegerType(), True),\n",
    "    StructField('weather_city_name', StringType(), True),\n",
    "    StructField('temp', DoubleType(), True),\n",
    "    StructField('pressure', IntegerType(), True),\n",
    "    StructField('humidity', IntegerType(), True),\n",
    "    StructField('wind_speed', IntegerType(), True),\n",
    "    StructField('wind_deg', IntegerType(), True),\n",
    "    StructField('rain_3h', DoubleType(), True),\n",
    "    StructField('clouds_all', IntegerType(), True),\n",
    "    StructField('weather_id', IntegerType(), True),\n",
    "    StructField('weather_main', StringType(), True),\n",
    "    StructField('weather_description', StringType(), True),    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- atm_id: integer (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(\"hdfs://10.0.0.227:8020/user/root/SRC_ATM_TRANS_to_HDFS/part-m-00000\", schema = fileSchema, header=False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **** Check count after importing data into a dataframe. ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question: Check count after importing data into a dataframe\n",
    "#Solution: After importing data into dataframe got the count of 2468572 records.\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **** Check count for the Location Dimension. ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-------------+-------+------+------+-----------+\n",
      "|            location|      streetname|street_number|zipcode|   lat|   lon|location_id|\n",
      "+--------------------+----------------+-------------+-------+------+------+-----------+\n",
      "|               Vadum|  Ellehammersvej|           43|   9430|57.118| 9.861|          0|\n",
      "|            Slagelse| Mariendals Alle|           29|   4200|55.398|11.342|          1|\n",
      "|          Fredericia|SjÃƒÂ¦llandsgade|           33|   7000|55.564| 9.757|          2|\n",
      "|             Kolding|        Vejlevej|          135|   6000|55.505| 9.457|          3|\n",
      "|   HÃƒÂ¸rning Hallen|        Toftevej|           53|   8362|56.091|10.033|          4|\n",
      "|                Aars| Himmerlandsgade|           70|   9600|56.803| 9.518|          5|\n",
      "|     Aarhus Lufthavn| Ny Lufthavnsvej|           24|   8560|56.308|10.627|          6|\n",
      "|                 Fur|      StenÃƒÂ¸re|           19|   7884|56.805|  9.02|          7|\n",
      "|            Hasseris|     Hasserisvej|          113|   9000|57.044| 9.898|          8|\n",
      "|Intern  KÃƒÂ¸benhavn|RÃƒÂ¥dhuspladsen|           75|   1550|55.676|12.571|          9|\n",
      "|      Skelagervej 15|     Skelagervej|           15|   9000|57.023| 9.891|         10|\n",
      "|    Intern HolbÃƒÂ¦k|     Slotsvolden|            7|   4300|55.718|11.704|         11|\n",
      "|              Viborg|       Toldboden|            3|   8800|56.448| 9.401|         12|\n",
      "|             SÃƒÂ¦by|      Vestergade|            3|   9300|57.334|10.515|         13|\n",
      "|             Aabybro|    ÃƒËœstergade|            6|   9440|57.162|  9.73|         14|\n",
      "|             Vodskov|      Vodskovvej|           27|   9310|57.104|10.027|         15|\n",
      "|               Taars|        Bredgade|           91|   9830|57.385|10.116|         16|\n",
      "|         Skive Lobby|        Adelgade|            8|   7800|56.567| 9.027|         17|\n",
      "|        HelsingÃƒÂ¸r|  Sct. Olai Gade|           39|   3000|56.036|12.612|         18|\n",
      "|             Jebjerg|       Kirkegade|            4|   7870|56.671| 9.013|         19|\n",
      "+--------------------+----------------+-------------+-------+------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question: Check count for the Location Dimension\n",
    "#Solution: Count for Location Dimension is 109 records and is shown in the below result.\n",
    "\n",
    "# DIM_LOCATION\n",
    "\n",
    "df_loc1 = df.select('atm_location','atm_streetname','atm_street_number', 'atm_zipcode', 'atm_lat', 'atm_lon').distinct()\n",
    "df_loc2 = df_loc1.rdd.zipWithIndex().toDF()\n",
    "df_loc3 = df_loc2.select(col(\"_1.*\"),col(\"_2\").alias('location_id'))\n",
    "df_loc = df_loc3.withColumnRenamed(\"atm_location\",\"location\").withColumnRenamed(\"atm_streetname\",\"streetname\").withColumnRenamed(\"atm_street_number\",\"street_number\").withColumnRenamed(\"atm_zipcode\",\"zipcode\").withColumnRenamed(\"atm_lat\",\"lat\").withColumnRenamed(\"atm_lon\",\"lon\")\n",
    "df_loc.show()\n",
    "df_loc.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **** Check count for the ATM Dimension. ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+---------------+------+\n",
      "|atm_number|atm_manufacturer|atm_location_id|atm_id|\n",
      "+----------+----------------+---------------+------+\n",
      "|       100|             NCR|             69|     0|\n",
      "|        73|             NCR|             84|     1|\n",
      "|        11|             NCR|             76|     2|\n",
      "|        97|             NCR|             86|     3|\n",
      "|        13|             NCR|             13|     4|\n",
      "|        20|             NCR|             95|     5|\n",
      "|        64|             NCR|             61|     6|\n",
      "|       109| Diebold Nixdorf|             34|     7|\n",
      "|       113| Diebold Nixdorf|              1|     8|\n",
      "|        88|             NCR|             92|     9|\n",
      "|        34|             NCR|             42|    10|\n",
      "|        97|             NCR|             45|    11|\n",
      "|        63|             NCR|             77|    12|\n",
      "|        14|             NCR|             94|    13|\n",
      "|        88|             NCR|             65|    14|\n",
      "|        17|             NCR|             47|    15|\n",
      "|        27|             NCR|             51|    16|\n",
      "|       112| Diebold Nixdorf|             73|    17|\n",
      "|        99|             NCR|             52|    18|\n",
      "|       102|             NCR|             65|    19|\n",
      "+----------+----------------+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question: Check count for the ATM Dimension\n",
    "#Solution: Count for ATM Dimension is 156 records and is shown in the below table.\n",
    "\n",
    "# DIM_ATM\n",
    "\n",
    "left_join = df.join(df_loc, [(df_loc.lat == df.atm_lat) & (df_loc.lon == df.atm_lon)], how='left').select('atm_id','atm_manufacturer', 'location_id')\n",
    "df_atm1 = left_join.withColumnRenamed(\"atm_id\", \"atm_number\").withColumnRenamed(\"location_id\", \"atm_location_id\").distinct()\n",
    "df_atm2 = df_atm1.rdd.zipWithIndex().toDF()\n",
    "df_atm = df_atm2.select(col(\"_1.*\"),col(\"_2\").alias('atm_id'))\n",
    "df_atm.show()\n",
    "df_atm.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **** Check count for the Date Dimension. ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+----+--------+-------+\n",
      "|year|   month|day|hour| weekday|date_id|\n",
      "+----+--------+---+----+--------+-------+\n",
      "|2017| January|  1|   9|  Sunday|      0|\n",
      "|2017| January|  3|   5| Tuesday|      1|\n",
      "|2017| January|  8|  19|  Sunday|      2|\n",
      "|2017| January| 21|   3|Saturday|      3|\n",
      "|2017| January| 23|  21|  Monday|      4|\n",
      "|2017|February|  2|  19|Thursday|      5|\n",
      "|2017|February|  5|  16|  Sunday|      6|\n",
      "|2017|February| 21|  15| Tuesday|      7|\n",
      "|2017|   March|  2|   8|Thursday|      8|\n",
      "|2017|   April|  2|   2|  Sunday|      9|\n",
      "|2017|   April|  6|   8|Thursday|     10|\n",
      "|2017|   April| 30|  10|  Sunday|     11|\n",
      "|2017|     May|  2|   2| Tuesday|     12|\n",
      "|2017|     May| 20|  16|Saturday|     13|\n",
      "|2017|     May| 21|  19|  Sunday|     14|\n",
      "|2017|    June| 27|   0| Tuesday|     15|\n",
      "|2017|    July| 18|   9| Tuesday|     16|\n",
      "|2017|    July| 18|  22| Tuesday|     17|\n",
      "|2017|    July| 20|   0|Thursday|     18|\n",
      "|2017|    July| 21|  19|  Friday|     19|\n",
      "+----+--------+---+----+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8685"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question : Check count for the Date Dimension\n",
    "#Solution : Count for Date Dimension is 8685 records and is shown in the below table.\n",
    "\n",
    "# DIM_DATE\n",
    "\n",
    "df_date1 = df.select('year','month','day','hour','weekday').distinct()\n",
    "df_date2 = df_date1.rdd.zipWithIndex().toDF()\n",
    "df_date = df_date2.select(col(\"_1.*\"),col(\"_2\").alias('date_id'))\n",
    "df_date.show()\n",
    "df_date.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **** Check count for the Card Type Dimension. ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           card_type|card_type_id|\n",
      "+--------------------+------------+\n",
      "|     Dankort - on-us|           0|\n",
      "|              CIRRUS|           1|\n",
      "|         HÃƒÂ¦vekort|           2|\n",
      "|                VISA|           3|\n",
      "|  Mastercard - on-us|           4|\n",
      "|             Maestro|           5|\n",
      "|Visa Dankort - on-us|           6|\n",
      "|        Visa Dankort|           7|\n",
      "|            VisaPlus|           8|\n",
      "|          MasterCard|           9|\n",
      "|             Dankort|          10|\n",
      "| HÃƒÂ¦vekort - on-us|          11|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question : Check count for the Card Type Dimension\n",
    "#Solution : COunt for Card type dimension is 12 records and is shown in the below table.\n",
    "\n",
    "# DIM_CARD_TYPE\n",
    "\n",
    "df_ct1 = df.select('card_type').distinct()\n",
    "df_ct2 = df_ct1.rdd.zipWithIndex().toDF()\n",
    "df_ct = df_ct2.select(col(\"_1.*\"),col(\"_2\").alias('card_type_id'))\n",
    "df_ct.show()\n",
    "df_ct.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **** Check count for the all the Stages in the creation of Transaction Fact table. ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+------------------+------------+------------+-------+----------+----------+------------+-------------------+--------------+-------+------------+------+--------+\n",
      "|atm_status|currency|   service|transaction_amount|message_code|message_text|rain_3h|clouds_all|weather_id|weather_main|weather_description|weather_loc_id|date_id|card_type_id|atm_id|trans_id|\n",
      "+----------+--------+----------+------------------+------------+------------+-------+----------+----------+------------+-------------------+--------------+-------+------------+------+--------+\n",
      "|    Active|     DKK|Withdrawal|              2041|        null|        null|    0.0|        44|       802|      Clouds|   scattered clouds|            23|   2235|           0|   143|       0|\n",
      "|    Active|     DKK|Withdrawal|              7831|        null|        null|    0.0|        44|       802|      Clouds|   scattered clouds|            23|   2235|           0|   143|       1|\n",
      "|    Active|     DKK|Withdrawal|              4087|        null|        null|    0.0|        44|       802|      Clouds|   scattered clouds|            23|   2235|           0|   143|       2|\n",
      "|    Active|     DKK|Withdrawal|                62|        null|        null|    0.0|        44|       802|      Clouds|   scattered clouds|            23|   2235|           0|   143|       3|\n",
      "|    Active|     DKK|Withdrawal|              6202|        null|        null|    0.0|        44|       802|      Clouds|   scattered clouds|            23|   2235|           0|   143|       4|\n",
      "|    Active|     DKK|Withdrawal|              5251|        null|        null|    0.0|        75|       521|        Rain|        shower rain|            23|   6665|           0|   143|       5|\n",
      "|    Active|     DKK|Withdrawal|              5676|        null|        null|   0.66|        88|       500|        Rain|         light rain|            23|   3240|           0|   143|       6|\n",
      "|    Active|     DKK|Withdrawal|              4492|        null|        null|    0.0|        68|       803|      Clouds|      broken clouds|            23|   3403|           0|   143|       7|\n",
      "|    Active|     DKK|Withdrawal|              4656|        null|        null|    0.0|        75|       803|      Clouds|      broken clouds|            23|   1607|           0|   143|       8|\n",
      "|    Active|     DKK|Withdrawal|               686|        null|        null|    0.0|        20|       801|      Clouds|         few clouds|            23|   6702|           0|   143|       9|\n",
      "|    Active|     DKK|Withdrawal|              1841|        null|        null|   0.41|        88|       500|        Rain|         light rain|            23|   5301|           0|   143|      10|\n",
      "|    Active|     DKK|Withdrawal|              6989|        null|        null|    0.0|        88|       804|      Clouds|    overcast clouds|            23|   7078|           0|   143|      11|\n",
      "|    Active|     DKK|Withdrawal|              4742|        null|        null|    0.0|         0|       800|       Clear|       Sky is Clear|            23|    935|           0|   143|      12|\n",
      "|    Active|     DKK|Withdrawal|              4384|        null|        null|    0.0|       100|       804|      Clouds|    overcast clouds|            23|   6956|           0|   143|      13|\n",
      "|    Active|     DKK|Withdrawal|              6097|        null|        null|   0.31|        24|       500|        Rain|         light rain|            23|   6527|           0|   143|      14|\n",
      "|    Active|     DKK|Withdrawal|               805|        null|        null|    0.0|        88|       600|        Snow|         light snow|            23|   2590|           0|   143|      15|\n",
      "|    Active|     DKK|Withdrawal|              7420|        null|        null|    0.0|        76|       803|      Clouds|      broken clouds|            23|   4366|           0|   143|      16|\n",
      "|    Active|     DKK|Withdrawal|              4950|        null|        null|    0.0|        40|       802|      Clouds|   scattered clouds|            23|   1813|           0|   143|      17|\n",
      "|    Active|     DKK|Withdrawal|              6460|        null|        null|    0.0|        64|       803|      Clouds|      broken clouds|            23|   1805|           0|   143|      18|\n",
      "|    Active|     DKK|Withdrawal|              2910|        null|        null|    0.0|        75|       500|        Rain|         light rain|            23|   3595|           0|   143|      19|\n",
      "+----------+--------+----------+------------------+------------+------------+-------+----------+----------+------------+-------------------+--------------+-------+------------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question : Check count for the all the Stages in the creation of Transaction Fact table\n",
    "#Solution : Count for Transaction fact tables is 2468572 and is shown in the below table.\n",
    "\n",
    "# FACT_ATM_TRANS \n",
    "\n",
    "left_join_fact1 = df.join(df_loc, [(df_loc.location == df.atm_location) & (df_loc.streetname == df.atm_streetname) & (df_loc.street_number == df.atm_street_number) & (df_loc.zipcode == df.atm_zipcode) & (df_loc.lat == df.atm_lat) & (df_loc.lon == df.atm_lon)], how='left')\n",
    "left_join_fact2 = left_join_fact1.join(df_date, [(df_date.year == df.year) & (df_date.month == df.month) & (df_date.day == df.day) & (df_date.weekday == df.weekday) & (df_date.hour == df.hour)], how='left')\n",
    "left_join_fact3 = left_join_fact2.join(df_ct, [(df_ct.card_type == df.card_type)], how='left')\n",
    "left_join_fact4 = left_join_fact3.join(df_atm, [(df_atm.atm_number == df.atm_id) & (df_atm.atm_manufacturer == df.atm_manufacturer) & (df_atm.atm_location_id == df_loc.location_id)], how='left')\n",
    "left_join_fact5 = left_join_fact4.select('atm_status','currency','service','transaction_amount','message_code','message_text','rain_3h','clouds_all','weather_id','weather_main','weather_description','atm_location_id','date_id','card_type_id',df_atm.atm_id)\n",
    "left_join_fact6 = left_join_fact5.withColumnRenamed(\"atm_location_id\", \"weather_loc_id\")\n",
    "\n",
    "df_fact2 = left_join_fact6.rdd.zipWithIndex().toDF(sampleRatio=0.01)\n",
    "df_fact = df_fact2.select(col(\"_1.*\"),col(\"_2\").alias('trans_id'))\n",
    "df_fact.show()\n",
    "df_fact.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ct.write.mode(\"overwrite\").option(\"header\",\"false\").csv(\"s3a://my-redshift-bucket-24/card_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc.write.mode(\"overwrite\").option(\"header\",\"false\").csv(\"s3a://my-redshift-bucket-24/location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atm.write.mode(\"overwrite\").option(\"header\",\"false\").csv(\"s3a://my-redshift-bucket-24/atm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.write.mode(\"overwrite\").option(\"header\",\"false\").csv(\"s3a://my-redshift-bucket-24/date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact.write.mode(\"overwrite\").option(\"header\",\"false\").csv(\"s3a://my-redshift-bucket-24/trans\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
